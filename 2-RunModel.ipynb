{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Badlands Glacial Model\n",
    "\n",
    "Welcome to the Badlands Glacier model, this Jupyter Notebook will demonstrate everything you need to know to get started exploring glaciers for yourself!\n",
    "\n",
    "Just like you can see below...\n",
    "\n",
    "## Landscapes modelling\n",
    "\n",
    "In this example, we simulate landscape evolution in response to three simple climatic scenarios: \n",
    "+ **fluvial** and\n",
    "+ **glaciated** and \n",
    "+ **Ice-capped**\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img width=\"1000\" alt=\"glaciers_model_closeup\" src=\"https://github.com/user-attachments/assets/0e2df5bd-2069-4f9b-ac36-4252c1802754\"\n",
    "    </img>\n",
    "</div>\n",
    "\n",
    "We investigate the drainage network dynamics and the steady-state fluvial patterns that emerge from an application of these climatic forcing mechanisms.\n",
    "\n",
    "The first part of the scenario starts from a flat topography subjected to a constant and uniform rate of tectonic rock uplift (>1 mm/a) and precipitation (1 m/a). The domain is rectangular and the four edges are kept at a constant base-level elevation. The area is a 40x80 km domain. \n",
    "\n",
    "After 8 Ma, the second scenario is applied and consists in a linearly varying rainfall pattern corresponding to an orographic precipitation with the same uniform tectonic uplift rate. The Northern part of the domain is experiencing a 2 m/a precipitation rate and the Southern part is subject to a 0.1 m/a precipitation rate for the next 12 Ma. \n",
    "\n",
    "## Initial settings\n",
    "\n",
    "For this model, we use the *stream power law sediment transport model* which scale the incision rate $E$ as a power function of surface water discharge $A$ and slope $S=\\nabla z$:\n",
    "\n",
    "$$ E = \\kappa A^m (\\nabla z)^n$$\n",
    "\n",
    "where $\\kappa$ is the erodibility coefficient dependent on lithology and mean precipitation rate, channel width, flood frequency, channel hydraulics.\n",
    "\n",
    "The values given to these parameters ($\\kappa$, $m$, $n$) need to be set in the **XmL** input file.\n",
    "\n",
    "For this particular setting we do not need to record any deposition as the model is purely erosive. To speed up the model we turn off the deposition computation in **badlands** by setting the **dep** element to *0* in the input file. \n",
    "\n",
    "## Starting badlands\n",
    "\n",
    "First we initialise the model and set the path to the **XmL** input file.\n",
    "\n",
    "\n",
    "> You can edit the **XmL** configuration file at [mountain.xml](mountain.xml) by changing the url from:\n",
    "+ http://localhost:32771/files/share/.../mountain.xml to \n",
    "+ http://localhost:32771/edit/share/.../mountain.xml\n",
    "where `files` has been modified to `edit`. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">To view the complete <b>XmL</b> options you can look at the documentation: <a href=\"https://badlands.readthedocs.io/en/latest/xml.html\"><b>badlands readthedoc</b></a>.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Badlands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from badlands.model import Model as badlandsModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting badlands\n",
    "\n",
    "First, we initialise the model and set the path to the **XmL** input file:\n",
    "\n",
    "+ **strati.xml**\n",
    "\n",
    "> You can edit the **XmL** configuration file directly in the _Jupyter environment_ by clicking on it in the `tree` and changing in the **url** the **view** to **edit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey Matt!, this is the badlands-workspace instance. Now with glaciers!\n",
      "Glaciers Found\n",
      "hTerm:  500.0\n",
      "hEla:  700.0\n",
      "KIce:  5e-06\n",
      "smth:  0.01\n",
      "ice_max:  100.0\n",
      "ice_spread:  85.0\n"
     ]
    }
   ],
   "source": [
    "model = badlandsModel()\n",
    "model.load_xml('input.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.000000000000004"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.elevation.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.999999999999996"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.elevation.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.force.hTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Badlands Model!\n",
    "\n",
    "We can run the model for a given period. The end time in the **XmL** input file is set to _6 Ma_ but you might want to run the model for a coupled of iterations and check the output before running the model for the entire simulation time. This is done by putting the time in the **run_to_time** function. \n",
    "\n",
    "Here we go for the full time directly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Writing outputs (0.09 seconds; tNow = 0.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 250000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 500000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 750000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 1000000.0)\n",
      "   - Writing outputs (0.10 seconds; tNow = 1250000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 1500000.0)\n",
      "   - Writing outputs (0.15 seconds; tNow = 1750000.0)\n",
      "   - Writing outputs (0.13 seconds; tNow = 2000000.0)\n",
      "   - Writing outputs (0.11 seconds; tNow = 2250000.0)\n",
      "   - Writing outputs (0.11 seconds; tNow = 2500000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 2750000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 3000000.0)\n",
      "   - Writing outputs (0.10 seconds; tNow = 3250000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 3500000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 3750000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 4000000.0)\n",
      "   - Writing outputs (0.11 seconds; tNow = 4250000.0)\n",
      "   - Writing outputs (0.13 seconds; tNow = 4500000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 4750000.0)\n",
      "tNow = 5000000 (0.10 seconds)\n",
      "   - Writing outputs (0.11 seconds; tNow = 5000000)\n"
     ]
    }
   ],
   "source": [
    "model.run_to_time(5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fluvial System Mountain Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey Matt!, this is the badlands-workspace instance. Now with glaciers!\n",
      "Glaciers Found\n",
      "hTerm:  50000.0\n",
      "hEla:  70000.0\n",
      "KIce:  5e-06\n",
      "smth:  0.01\n",
      "ice_max:  100.0\n",
      "ice_spread:  85.0\n"
     ]
    }
   ],
   "source": [
    "model = badlandsModel()\n",
    "model.load_xml('fluvial.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Writing outputs (0.08 seconds; tNow = 0.0)\n",
      "   - Writing outputs (0.10 seconds; tNow = 250000.0)\n",
      "   - Writing outputs (0.07 seconds; tNow = 500000.0)\n",
      "   - Writing outputs (0.12 seconds; tNow = 750000.0)\n",
      "   - Writing outputs (0.10 seconds; tNow = 1000000.0)\n",
      "   - Writing outputs (0.10 seconds; tNow = 1250000.0)\n",
      "   - Writing outputs (0.10 seconds; tNow = 1500000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 1750000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 2000000.0)\n",
      "   - Writing outputs (0.13 seconds; tNow = 2250000.0)\n",
      "   - Writing outputs (0.10 seconds; tNow = 2500000.0)\n",
      "   - Writing outputs (0.10 seconds; tNow = 2750000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 3000000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 3250000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 3500000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 3750000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 4000000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 4250000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 4500000.0)\n",
      "   - Writing outputs (0.07 seconds; tNow = 4750000.0)\n",
      "tNow = 5000000 (0.08 seconds)\n",
      "   - Writing outputs (0.07 seconds; tNow = 5000000)\n"
     ]
    }
   ],
   "source": [
    "model.run_to_time(5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ice-Capped Mountain Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey Matt!, this is the badlands-workspace instance. Now with glaciers!\n",
      "Glaciers Found\n",
      "hTerm:  500.0\n",
      "hEla:  700.0\n",
      "KIce:  5e-06\n",
      "smth:  0.05\n",
      "ice_max:  100.0\n",
      "ice_spread:  85.0\n",
      "KCap:  3e-06\n",
      "hIcecap:  1000.0\n"
     ]
    }
   ],
   "source": [
    "model = badlandsModel()\n",
    "model.load_xml('icecap.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   - Writing outputs (0.09 seconds; tNow = 0.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 250000.0)\n",
      "   - Writing outputs (0.10 seconds; tNow = 500000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 750000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 1000000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 1250000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 1500000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 1750000.0)\n",
      "   - Writing outputs (0.10 seconds; tNow = 2000000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 2250000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 2500000.0)\n",
      "   - Writing outputs (0.10 seconds; tNow = 2750000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 3000000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 3250000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 3500000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 3750000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 4000000.0)\n",
      "   - Writing outputs (0.09 seconds; tNow = 4250000.0)\n",
      "   - Writing outputs (0.11 seconds; tNow = 4500000.0)\n",
      "   - Writing outputs (0.08 seconds; tNow = 4750000.0)\n",
      "tNow = 5000000 (0.09 seconds)\n",
      "   - Writing outputs (0.09 seconds; tNow = 5000000)\n"
     ]
    }
   ],
   "source": [
    "model.run_to_time(5000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphometric and Hydrometric Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selv tak\n"
     ]
    }
   ],
   "source": [
    "print(\"Selv tak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
